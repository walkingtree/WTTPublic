{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to access a dataset to be used for customer churn. \n",
    "# One such dataset is available with the Sagemaker sample files set, and the following code can be used to download it \n",
    "# and push to S3 repository for further use in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.txt ./\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import pandas as pd\n",
    "prefix = 'sagemaker/DEMO-xgboost-churn'\n",
    "region = boto3.Session().region_name\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "RawData = boto3.Session().resource('s3')\\\n",
    ".Bucket(default_bucket).Object(os.path.join(prefix, 'data/RawData.csv'))\\\n",
    ".upload_file('./churn.txt')\n",
    "print(os.path.join(\"s3://\",default_bucket, prefix, 'data/RawData.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ‘code’ folder. This will be used to house the preprocessing and the evaluation scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing code is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/preprocess.py\n",
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n",
    "# may not use this file except in compliance with the License. A copy of\n",
    "# the License is located at\n",
    "#\n",
    "#     http://aws.amazon.com/apache2.0/\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is\n",
    "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n",
    "# ANY KIND, either express or implied. See the License for the specific\n",
    "# language governing permissions and limitations under the License.\n",
    "\"\"\"Feature engineers the customer churn dataset.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting preprocessing.\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    pathlib.Path(f\"{base_dir}/data\").mkdir(parents=True, exist_ok=True)\n",
    "    input_data = args.input_data\n",
    "    print(input_data)\n",
    "    bucket = input_data.split(\"/\")[2]\n",
    "    key = \"/\".join(input_data.split(\"/\")[3:])\n",
    "\n",
    "    logger.info(\"Downloading data from bucket: %s, key: %s\", bucket, key)\n",
    "    fn = f\"{base_dir}/data/raw-data.csv\"\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.Bucket(bucket).download_file(key, fn)\n",
    "\n",
    "    logger.info(\"Reading downloaded data.\")\n",
    "\n",
    "    # read in csv\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    # drop the \"Phone\" feature column\n",
    "    df = df.drop([\"Phone\"], axis=1)\n",
    "\n",
    "    # Change the data type of \"Area Code\"\n",
    "    df[\"Area Code\"] = df[\"Area Code\"].astype(object)\n",
    "\n",
    "    # Drop several other columns\n",
    "    df = df.drop([\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\"], axis=1)\n",
    "\n",
    "    # Convert categorical variables into dummy/indicator variables.\n",
    "    model_data = pd.get_dummies(df)\n",
    "\n",
    "    # Create one binary classification target column\n",
    "    model_data = pd.concat(\n",
    "        [\n",
    "            model_data[\"Churn?_True.\"],\n",
    "            model_data.drop([\"Churn?_False.\", \"Churn?_True.\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Split the data\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(model_data)), int(0.9 * len(model_data))],\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(train_data).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation_data).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test_data).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The evaluate.py, used to evaluate the model, is listed hereunder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/evaluate.py\n",
    "\n",
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n",
    "# may not use this file except in compliance with the License. A copy of\n",
    "# the License is located at\n",
    "#\n",
    "#     http://aws.amazon.com/apache2.0/\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is\n",
    "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n",
    "# ANY KIND, either express or implied. See the License for the specific\n",
    "# language governing permissions and limitations under the License.\n",
    "\"\"\"Evaluation script for measuring model accuracy.\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "# May need to import additional metrics depending on what you are measuring.\n",
    "# See https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\"..\")\n",
    "\n",
    "    logger.debug(\"Loading xgboost model.\")\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    print(\"Loading test input data\")\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    logger.debug(\"Reading test data.\")\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    logger.info(\"Performing predictions against test data.\")\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print(\"Creating classification evaluation report\")\n",
    "    acc = accuracy_score(y_test, predictions.round())\n",
    "    auc = roc_auc_score(y_test, predictions.round())\n",
    "\n",
    "    # The metrics reported can change based on the model used, but it must be a specific name per (https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)\n",
    "    report_dict = {\n",
    "        \"binary_classification_metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": acc,\n",
    "                \"standard_deviation\": \"NaN\",\n",
    "            },\n",
    "            \"auc\": {\"value\": auc, \"standard_deviation\": \"NaN\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"Classification report:\\n{}\".format(report_dict))\n",
    "\n",
    "    evaluation_output_path = os.path.join(\"/opt/ml/processing/evaluation\", \"evaluation.json\")\n",
    "    print(\"Saving classification report to {}\".format(evaluation_output_path))\n",
    "\n",
    "    with open(evaluation_output_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main pipeline components are defined in the pipeline.py file as below : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n",
    "# may not use this file except in compliance with the License. A copy of\n",
    "# the License is located at\n",
    "#\n",
    "#     http://aws.amazon.com/apache2.0/\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is\n",
    "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n",
    "# ANY KIND, either express or implied. See the License for the specific\n",
    "# language governing permissions and limitations under the License.\n",
    "\"\"\"Example workflow pipeline script for CustomerChurn pipeline.\n",
    "                                               . -RegisterModel\n",
    "                                              .\n",
    "    Process-> Train -> Evaluate -> Condition .\n",
    "                                              .\n",
    "                                               . -(stop)\n",
    "Implements a get_pipeline(**kwargs) method.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "\n",
    "print('IMPORT DONE')\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "print('BOTO DONE')\n",
    "#def get_pipeline(\n",
    " #   region,\n",
    "role=None\n",
    "#role = get_execution_role(),\n",
    "#default_bucket=None,\n",
    "model_package_group_name=\"CustomerChurnPackageGroup\"  # Choose any name\n",
    "pipeline_name=\"CustomerChurnDemo-p-ewf8t7lvhivm\"  # You can find your pipeline name in the Studio UI (project -> Pipelines -> name)\n",
    "base_job_prefix=\"CustomerChurn\"  # Choose any name\n",
    "\n",
    "print('DEFAULT BUCKET: ',default_bucket)\n",
    "#sagemaker_session = get_session(region, None)\n",
    "#print('SAGEMAKER SESSION: ', sagemaker_session)\n",
    "sagemaker_session = get_session(region, default_bucket)\n",
    "print('ROLE ORIGINAL: ', role)\n",
    "if role is None:\n",
    "    role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "    print('ROLE : ', role)\n",
    "\n",
    "\n",
    "    # Parameters for pipeline execution\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "model_approval_status = ParameterString(\n",
    "        name=\"ModelApprovalStatus\",\n",
    "        default_value=\"PendingManualApproval\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    "    )\n",
    "input_data = ParameterString(\n",
    "        name=\"InputDataUrl\",\n",
    "        default_value=f\"s3://sagemaker-ap-south-1-266441554743/sagemaker/DEMO-xgboost-churn/data/RawData.csv\",  # Change this to point to the s3 location of your raw input data.\n",
    "    )\n",
    "\n",
    "print('PARAMETER STRING DEFINITION')\n",
    "    # Processing step for feature engineering\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=\"0.23-1\",\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count=processing_instance_count,\n",
    "        base_job_name=f\"{base_job_prefix}/sklearn-CustomerChurn-preprocess\",  # choose any name\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "        name=\"CustomerChurnProcess\",  # choose any name\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "        ],\n",
    "        code=\"code/preprocess.py\",\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    "    )\n",
    "\n",
    "\n",
    "print('step_process DEFINITION')\n",
    "    # Training step for generating model artifacts\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "        framework=\"xgboost\",  # we are using the Sagemaker built in xgboost algorithm\n",
    "        region=region,\n",
    "        version=\"1.0-1\",\n",
    "        py_version=\"py3\",\n",
    "        instance_type=training_instance_type,\n",
    "    )\n",
    "xgb_train = Estimator(\n",
    "        image_uri=image_uri,\n",
    "        instance_type=training_instance_type,\n",
    "        instance_count=1,\n",
    "        output_path=model_path,\n",
    "        base_job_name=f\"{base_job_prefix}/CustomerChurn-train\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    )\n",
    "xgb_train.set_hyperparameters(\n",
    "        objective=\"binary:logistic\",\n",
    "        num_round=50,\n",
    "        max_depth=5,\n",
    "        eta=0.2,\n",
    "        gamma=4,\n",
    "        min_child_weight=6,\n",
    "        subsample=0.7,\n",
    "        silent=0,\n",
    "    )\n",
    "\t\n",
    "print('TRAINING STEP DEFINITION')\n",
    "\n",
    "step_train = TrainingStep(\n",
    "        name=\"CustomerChurnTrain\",\n",
    "        estimator=xgb_train,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "        image_uri=image_uri,\n",
    "        command=[\"python3\"],\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}/script-CustomerChurn-eval\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    )\n",
    "evaluation_report = PropertyFile(\n",
    "        name=\"EvaluationReport\",\n",
    "        output_name=\"evaluation\",\n",
    "        path=\"evaluation.json\",\n",
    "    )\n",
    "step_eval = ProcessingStep(\n",
    "        name=\"CustomerChurnEval\",\n",
    "        processor=script_eval,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "        ],\n",
    "        #code=os.path.join(BASE_DIR, \"evaluate.py\"),\n",
    "        code=\"code/evaluate.py\",\n",
    "        property_files=[evaluation_report],\n",
    "    )\n",
    "print('EVALUATION STEP DEFINITION')\n",
    "    # Register model step that will be conditionally execute\n",
    "\n",
    "model_path = f\"s3://{bucket}/{base_job_prefix}/CustomerChurnTrain\"\n",
    "\t\n",
    "# Register model step that will be conditionally executed\n",
    "model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            s3_uri=\"{}/evaluation.json\".format(\n",
    "                step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "            ),\n",
    "            content_type=\"application/json\",\n",
    "        )\n",
    "    )\n",
    "    # Register model step that will be conditionally executed\n",
    "step_register = RegisterModel(\n",
    "        name=\"CustomerChurnRegisterModel\",\n",
    "        estimator=xgb_train,\n",
    "        model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=model_approval_status,\n",
    "        model_metrics=model_metrics,\n",
    "    )\n",
    "\n",
    "    # Condition step for evaluating model quality and branching execution\n",
    "cond_lte = ConditionGreaterThanOrEqualTo(  # You can change the condition here\n",
    "        left=JsonGet(\n",
    "            step=step_eval,\n",
    "            property_file=evaluation_report,\n",
    "            json_path=\"binary_classification_metrics.accuracy.value\",  # This should follow the structure of your report_dict defined in the evaluate.py file.\n",
    "        ),\n",
    "        right=0.8,  # You can change the threshold here\n",
    "    )\n",
    "step_cond = ConditionStep(\n",
    "        name=\"CustomerChurnAccuracyCond\",\n",
    "        conditions=[cond_lte],\n",
    "        if_steps=[step_register],\n",
    "        else_steps=[],\n",
    "    )\n",
    "\n",
    "    # Pipeline instance\n",
    "pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            model_approval_status,\n",
    "            input_data,\n",
    "        ],\n",
    "        steps=[step_process, step_train, step_eval, step_cond],\n",
    "        #steps=[step_process],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipeline definition is loaded as below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "definition = json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipeline is submitted to Sagemaker through the upsert method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the pipeline is executed as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the status of execution of the pipeline, i.e. whether it is finished or not, use :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To deploy the latest approved model to an endpoint, the following code should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "import argparse\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_approved_package(model_package_group_name):\n",
    "    \"\"\"Gets the latest approved model package for a model package group.\n",
    "\n",
    "    Args:\n",
    "        model_package_group_name: The model package group name.\n",
    "\n",
    "    Returns:\n",
    "        The SageMaker Model Package ARN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the latest approved model package\n",
    "        response = sm_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        # Fetch more packages if none returned with continuation token\n",
    "        while len(approved_packages) == 0 and \"NextToken\" in response:\n",
    "            logger.debug(\"Getting more packages for token: {}\".format(response[\"NextToken\"]))\n",
    "            response = sm_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group_name,\n",
    "                ModelApprovalStatus=\"Approved\",\n",
    "                SortBy=\"CreationTime\",\n",
    "                MaxResults=100,\n",
    "                NextToken=response[\"NextToken\"],\n",
    "            )\n",
    "            approved_packages.extend(response[\"ModelPackageSummaryList\"])\n",
    "\n",
    "        # Return error if no packages found\n",
    "        if len(approved_packages) == 0:\n",
    "            error_message = (\n",
    "                f\"No approved ModelPackage found for ModelPackageGroup: {model_package_group_name}\"\n",
    "            )\n",
    "            logger.error(error_message)\n",
    "            raise Exception(error_message)\n",
    "\n",
    "        # Return the pmodel package arn\n",
    "        model_package_arn = approved_packages[0][\"ModelPackageArn\"]\n",
    "        logger.info(f\"Identified the latest approved model package: {model_package_arn}\")\n",
    "        return approved_packages[0]\n",
    "        # return model_package_arn\n",
    "    except ClientError as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"]\n",
    "        logger.error(error_message)\n",
    "        raise Exception(error_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_approved_package\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "pck = get_approved_package(model_package_group_name) # Reminder: model_package_group_name was defined as \"NominetAbaloneModelPackageGroupName\" at the beginning of the pipeline definition\n",
    "model_description = sm_client.describe_model_package(ModelPackageName=pck['ModelPackageArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "model_package_arn = model_description['ModelPackageArn']\n",
    "model = ModelPackage(role=role, \n",
    "                     model_package_arn=model_package_arn, \n",
    "                     sagemaker_session=sagemaker_session)\n",
    "\n",
    "endpoint_name = 'DEMO-endpoint-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"EndpointName= {}\".format(endpoint_name))\n",
    "model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tp test the endpoint, the following code may be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "predictor = Predictor(endpoint_name=endpoint_name)\n",
    "\n",
    "pred_count = 10\n",
    "payload = data.iloc[:pred_count].to_string(header=False, index=False).replace('  ',',')\n",
    "p = predictor.predict(payload, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "print(p.decode(\"utf-8\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
